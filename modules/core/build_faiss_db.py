"""
img í´ë”ì˜ PDF ë°ì´í„°ë¥¼ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì¦ë¶„ shard + merge êµ¬ì¡°)

img í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ:
- PDF íŒŒì¼ (PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
- Page*_answer.json (ì •ë‹µ JSON)

íŒŒì¼ì„ ì°¾ì•„ì„œ ë³€ê²½ë¶„ë§Œ shardë¡œ ìƒì„±í•˜ê³  base DBì— mergeí•©ë‹ˆë‹¤.
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import fitz  # PyMuPDF

from modules.core.rag_manager import get_rag_manager
from modules.utils.config import get_project_root, get_extraction_method_for_upload_channel, folder_name_to_upload_channel
from modules.utils.hash_utils import compute_page_hash, get_page_key, compute_file_fingerprint
from modules.utils.db_manifest_manager import DBManifestManager
from modules.utils.pdf_utils import PdfTextExtractor


def find_pdf_pages(
    img_dir: Path,
    form_folder: Optional[str] = None,
) -> List[Dict[str, Any]]:
    """
    img í´ë”ì˜ í•˜ìœ„ í´ë”(finet, mail, 01, 02 ë“±) ì•ˆì—ì„œ PDF í˜ì´ì§€ ë°ì´í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        img_dir: img í´ë” ê²½ë¡œ
        form_folder: í•˜ìœ„ í´ë”ëª… (ì˜ˆ: "finet", "mail"). Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë”ë¥¼ ìˆœíšŒ

    Returns:
        [page_data, ...] ë¦¬ìŠ¤íŠ¸
        page_data = {
            'pdf_name': str,
            'page_num': int,
            'pdf_path': Path,
            'answer_json_path': Optional[Path],
            'form_type': Optional[str],  # 01, 02, 03 ë“± ì–‘ì‹ ì½”ë“œ (ìˆìœ¼ë©´)
        }
    """
    pages = []

    # img í•˜ìœ„ í´ë” ëª©ë¡ (finet, mail ë“± ì±„ë„ë³„ ë˜ëŠ” 01, 02 ë“± - ëª¨ë‘ ëŒ€ìƒ)
    if form_folder:
        form_folders = [img_dir / form_folder]
    else:
        form_folders = sorted(
            [d for d in img_dir.iterdir() if d.is_dir() and not d.name.startswith(".")],
            key=lambda d: d.name,
        )

    for form_dir in form_folders:
        if not form_dir.exists():
            continue

        print(f"ğŸ“ í´ë”: {form_dir.name}")

        # ìƒìœ„ í´ë” ê¸°ì¤€ form_type í›„ë³´ (ê³¼ê±° êµ¬ì¡°: img/01/...)
        parent_form_type: Optional[str] = form_dir.name if form_dir.name.isdigit() else None

        # ê²€ìƒ‰ ë£¨íŠ¸ ê²°ì •: base > íƒ€ì…(01,02) í•˜ìœ„ > ì±„ë„ ì§í•˜ìœ„
        base_dir = form_dir / "base"
        if base_dir.exists() and base_dir.is_dir():
            search_dirs = [base_dir]
        else:
            first_children = [d for d in form_dir.iterdir() if d.is_dir() and not d.name.startswith(".")]
            # ì§í•˜ìœ„ì— "í´ë”ëª….pdf"ê°€ ìˆìœ¼ë©´ PDF í´ë”ê°€ ì§í•˜ìœ„ì— ìˆëŠ” êµ¬ì¡°
            has_direct_pdf = any((d / f"{d.name}.pdf").exists() for d in first_children)
            if has_direct_pdf:
                search_dirs = [form_dir]
            else:
                # finet/01, mail/02 ë“± íƒ€ì… í´ë” ì•ˆì—ì„œ PDF í´ë” ì°¾ê¸°
                search_dirs = list(first_children)

        for search_dir in search_dirs:
            # finet/01, mail/02 ë“±ì¼ ë•Œ í˜„ì¬ search_dirì´ ì–‘ì‹ ì½”ë“œ(01~05)ë¥¼ ë‚˜íƒ€ëƒ„
            current_form_type: Optional[str] = None
            if search_dir.name.isdigit():
                current_form_type = search_dir.name
            elif parent_form_type:
                # search_dirê°€ base/ë…„-ì›”/ ë“±ì˜ í•˜ìœ„ì¼ ë•Œ ìƒìœ„ í´ë”ëª…ì„ form_typeìœ¼ë¡œ ì‚¬ìš©
                current_form_type = parent_form_type

            # PDF í´ë”ë“¤ ìˆœíšŒ
            for pdf_folder in search_dir.iterdir():
                if not pdf_folder.is_dir() or pdf_folder.name == ".DS_Store":
                    continue

                pdf_name = pdf_folder.name
                pdf_file = pdf_folder / f"{pdf_name}.pdf"
                if not pdf_file.exists():
                    pdf_file = search_dir / f"{pdf_name}.pdf"

                if not pdf_file.exists():
                    print(f"  âš ï¸ PDF íŒŒì¼ ì—†ìŒ: {pdf_name}")
                    continue

                # ë²„ì „ êµ¬ë¶„ ì—†ì´ ëª¨ë“  Page*_answer*.json ëŒ€ìƒìœ¼ë¡œ ì²˜ë¦¬
                answer_files = sorted(pdf_folder.glob("Page*_answer*.json"))

                if not answer_files:
                    print(f"  âš ï¸ {pdf_name}: answer.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                    continue

                try:
                    doc = fitz.open(pdf_file)
                    page_count = len(doc)
                    doc.close()
                except Exception as e:
                    print(f"  âš ï¸ PDF íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({pdf_name}): {e}")
                    continue

                print(f"  - {pdf_name}: {len(answer_files)}ê°œ answer.json íŒŒì¼, {page_count}í˜ì´ì§€")

                for answer_file in answer_files:
                    try:
                        stem = answer_file.stem
                        import re
                        match = re.match(r'Page(\d+)_answer', stem)
                        if not match:
                            print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                            continue
                        page_num = int(match.group(1))

                        if page_num < 1 or page_num > page_count:
                            print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ ë²”ìœ„ ì´ˆê³¼: {pdf_name} Page{page_num} (ìµœëŒ€: {page_count})")
                            continue

                        pages.append({
                            'pdf_name': pdf_name,
                            'page_num': page_num,
                            'pdf_path': pdf_file,
                            'answer_json_path': answer_file,
                            'form_type': current_form_type,
                        })
                    except ValueError:
                        print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                        continue

    return pages




def load_answer_json(answer_path: Optional[Path]) -> Dict[str, Any]:
    """ì •ë‹µ JSON íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤."""
    if answer_path is None or not answer_path.exists():
        return {}

    try:
        with open(answer_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ì •ë‹µ JSON ì½ê¸° ì‹¤íŒ¨ ({answer_path}): {e}")
        return {}


def diff_pages_with_manifest(
    pages: List[Dict[str, Any]],
    manifest: DBManifestManager,
    text_extractor: PdfTextExtractor,
    text_extraction_method: str = "pymupdf"  # "pymupdf" ë˜ëŠ” "excel"
) -> List[Dict[str, Any]]:
    """
    manifestì™€ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    2ë‹¨ê³„ ì²´í¬: 1ë‹¨ê³„(answer.json fingerprint) â†’ 2ë‹¨ê³„(ì‹¤ì œ í…ìŠ¤íŠ¸ hash)
    staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ.

    Args:
        pages: í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        manifest: DBManifestManager ì¸ìŠ¤í„´ìŠ¤
        text_extractor: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (ìºì‹± ì§€ì›)

    Returns:
        ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
    """
    new_pages = []

    for page_data in pages:
        pdf_name = page_data['pdf_name']
        page_num = page_data['page_num']
        pdf_path = page_data['pdf_path']
        answer_path = page_data.get('answer_json_path')

        if not answer_path or not answer_path.exists():
            continue

        pdf_filename = f"{pdf_name}.pdf"  # DBëŠ” í™•ì¥ì í¬í•¨
        page_key = get_page_key(pdf_name, page_num)

        # staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        if manifest.is_staged(pdf_filename, page_num):
            continue

        # 1ë‹¨ê³„: answer.json fingerprint ì²´í¬
        fingerprint = compute_file_fingerprint(pdf_path, answer_path)
        if not manifest.is_file_changed_fast(pdf_filename, page_num, fingerprint):
            continue

        # 2ë‹¨ê³„: ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° hash ê³„ì‚°
        # text_extractor.extract_text()ê°€ methodì— ë”°ë¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        # "excel" ë°©ë²•ì€ pdfplumberë¡œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•¨ (í…Œì´ë¸”ë§Œì´ ì•„ë‹˜)
        ocr_text = text_extractor.extract_text(pdf_path, page_num)

        if not ocr_text:
            continue

        answer_json = load_answer_json(answer_path)
        if not answer_json:
            continue

        page_hash = compute_page_hash(ocr_text, answer_json)

        # merged ìƒíƒœì´ê³  hash ë™ì¼í•˜ë©´ ìŠ¤í‚µ
        if manifest.is_processed(pdf_filename, page_num, page_hash):
            continue

        # ìƒˆë¡œìš´ í˜ì´ì§€ì´ê±°ë‚˜ ë³€ê²½ë¨
        new_pages.append({
            **page_data,
            'ocr_text': ocr_text,
            'answer_json': answer_json,
            'page_hash': page_hash,
            'page_key': page_key,
            'fingerprint': fingerprint,
            'pdf_filename': pdf_filename  # DBìš© íŒŒì¼ëª… ì¶”ê°€
        })

    return new_pages


def detect_deleted_pages(
    scanned_pages: List[Dict[str, Any]],  # [{'pdf_name': str, 'page_num': int}, ...]
    manifest: DBManifestManager
) -> List[Dict[str, Any]]:
    """
    ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ (manifestì— ìˆì§€ë§Œ ìŠ¤ìº” ê²°ê³¼ì— ì—†ìŒ)

    Args:
        scanned_pages: í˜„ì¬ ìŠ¤ìº”ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        manifest: DBManifestManager ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ì‚­ì œëœ í˜ì´ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{'pdf_filename': str, 'page_number': int}, ...]
    """
    # ìŠ¤ìº”ëœ í˜ì´ì§€ë¥¼ (pdf_filename, page_number) ì§‘í•©ìœ¼ë¡œ ë³€í™˜
    scanned_set = {
        (f"{p['pdf_name']}.pdf", p['page_num'])
        for p in scanned_pages
    }

    # DBì—ì„œ ëª¨ë“  í˜ì´ì§€ ì¡°íšŒ
    try:
        with manifest.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pdf_filename, page_number, status
                FROM rag_learning_status_current
                WHERE status IN ('merged', 'staged')
            """)

            deleted_pages = []
            for row in cursor.fetchall():
                pdf_filename = row[0]
                page_number = row[1]
                status = row[2]

                # ìŠ¤ìº” ê²°ê³¼ì— ì—†ìœ¼ë©´ ì‚­ì œëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                if (pdf_filename, page_number) not in scanned_set:
                    deleted_pages.append({
                        'pdf_filename': pdf_filename,
                        'page_number': page_number
                    })

        return deleted_pages
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        print(f"âš ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        return []


def build_faiss_db(
    img_dir: Path = None,
    form_folder: Optional[str] = None,
    auto_merge: bool = False,
    text_extraction_method: str = "pymupdf"  # ê¸°ë³¸ê°’ (ì–‘ì‹ì§€ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œ ì‚¬ìš©)
) -> None:
    """
    img í´ë” í•˜ìœ„(finet, mail ë“±)ë¥¼ ìŠ¤ìº”í•˜ì—¬ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (ì¦ë¶„ shard + ë‹¨ì¼ ê¸€ë¡œë²Œ base).

    Args:
        img_dir: img í´ë” ê²½ë¡œ (Noneì´ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸/img)
        form_folder: í•˜ìœ„ í´ë”ëª… í•˜ë‚˜ë§Œ ì§€ì • (ì˜ˆ: "finet"). Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë” ìˆœíšŒ
        auto_merge: shard ìƒì„± í›„ baseì— ìë™ merge ì—¬ë¶€
        text_extraction_method: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ê¸°ë³¸ê°’ (config.form_extraction_methodì— ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    """
    if img_dir is None:
        project_root = get_project_root()
        img_dir = project_root / "img"

    if not img_dir.exists():
        print(f"âŒ img í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_dir}")
        return

    # RAG Manager ì´ˆê¸°í™”
    print("ğŸ”„ RAG Manager ì´ˆê¸°í™” ì¤‘...")
    try:
        rag_manager = get_rag_manager()
        # ë²¡í„°DBê°€ ì‚­ì œ í›„ ì¬ìƒì„±ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ
        print("ğŸ”„ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ ì¤‘ (ìµœì‹  ìƒíƒœ í™•ì¸)...")
        rag_manager.reload_index()
        print("âœ… RAG Manager ì´ˆê¸°í™” ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ RAG Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # DB Manifest Manager ì´ˆê¸°í™”
    manifest = DBManifestManager()

    print(f"ğŸ“‹ DB Manifest ë¡œë“œ: {len(manifest.get_all_page_keys())}ê°œ í˜ì´ì§€ ë“±ë¡ë¨\n")

    # form_folderê°€ Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë”(finet, mail ë“±) ìˆœíšŒ
    if form_folder:
        form_folders_to_process = [form_folder]
    else:
        form_folders_to_process = sorted(
            d.name for d in img_dir.iterdir()
            if d.is_dir() and not d.name.startswith(".")
        )

    # img í•˜ìœ„ ê° í´ë”(finet, mail ë“±) ì²˜ë¦¬
    for current_form_folder in form_folders_to_process:
        print(f"\n{'='*60}")
        print(f"ğŸ“‚ í´ë” '{current_form_folder}' ì²˜ë¦¬ ì¤‘")
        print(f"{'='*60}\n")

        # í´ë”ëª…ì„ upload_channelë¡œ ë³€í™˜ (form_type â†’ upload_channel ë§¤í•‘)
        upload_channel = folder_name_to_upload_channel(current_form_folder)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ê²°ì • (upload_channel ê¸°ë°˜)
        extraction_method = get_extraction_method_for_upload_channel(upload_channel)
        if extraction_method == text_extraction_method:
            pass
        print(f"ğŸ“ '{current_form_folder}' â†’ upload_channel: {upload_channel}, ì¶”ì¶œ ë°©ë²•: {extraction_method}\n")

        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„± (ìºì‹± ì§€ì›)
        text_extractor = PdfTextExtractor(method=extraction_method, upload_channel=upload_channel)

        pages = find_pdf_pages(img_dir, current_form_folder)
        if not pages:
            print(f"âš ï¸ í´ë” '{current_form_folder}'ì— ì²˜ë¦¬í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
            text_extractor.close_all()  # ìºì‹œ ì •ë¦¬
            continue

        print(f"âœ… {len(pages)}ê°œ í˜ì´ì§€ ë°œê²¬\n")

        try:
            # ì‚­ì œëœ í˜ì´ì§€ ê°ì§€
            deleted_pages = detect_deleted_pages(pages, manifest)
            if deleted_pages:
                print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€: {len(deleted_pages)}ê°œ")
                for deleted in deleted_pages[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                    print(f"   - {deleted['pdf_filename']} í˜ì´ì§€ {deleted['page_number']}")
                if len(deleted_pages) > 10:
                    print(f"   ... ì™¸ {len(deleted_pages) - 10}ê°œ")
                manifest.mark_pages_deleted(deleted_pages)

            # manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ë§Œ í•„í„°ë§
            print(f"ğŸ” Manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ í™•ì¸ ì¤‘... (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²•: {extraction_method})")
            new_pages = diff_pages_with_manifest(pages, manifest, text_extractor, extraction_method)

            if not new_pages:
                print(f"âœ… í´ë” '{current_form_folder}': ë³€ê²½ëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
                continue

            print(f"ğŸ“ ë³€ê²½ëœ í˜ì´ì§€: {len(new_pages)}ê°œ ë°œê²¬\n")

            # ê¸°ì¡´ ì˜ˆì œ ìˆ˜ í™•ì¸ (ì–‘ì‹ì§€ë³„)
            # TODO: count_examplesë„ form_typeë³„ë¡œ ì¹´ìš´íŠ¸í•˜ë„ë¡ ìˆ˜ì • í•„ìš”
            existing_count = rag_manager.count_examples()
            print(f"ğŸ“Š ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ\n")

            # shard ìƒì„±ì„ ìœ„í•œ í˜ì´ì§€ ë°ì´í„° ì¤€ë¹„
            shard_pages = []
            for page_data in new_pages:
                pdf_name = page_data['pdf_name']
                page_num = page_data['page_num']
                # í˜ì´ì§€ ë‹¨ìœ„ form_type (01~05 ë“±)ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í´ë”ëª… ê·¸ëŒ€ë¡œ
                page_form_type = page_data.get('form_type') or current_form_folder

                metadata = {
                    'pdf_name': pdf_name,
                    'page_num': page_num,
                    # upload_channel(finet/mail)ê³¼ form_type(01~05)ì„ ëª¨ë‘ ë©”íƒ€ë°ì´í„°ì— ì €ì¥
                    'upload_channel': upload_channel,
                    'form_type': page_form_type,
                    'source': 'img_folder'
                }

                shard_pages.append({
                    'pdf_name': pdf_name,
                    'page_num': page_num,
                    'ocr_text': page_data['ocr_text'],
                    'answer_json': page_data['answer_json'],
                    'metadata': metadata,
                    'page_key': page_data['page_key'],
                    'page_hash': page_data['page_hash']
                })

            # shard FAISS DB ìƒì„± (ë‹¨ì¼ ê¸€ë¡œë²Œ ì¸ë±ìŠ¤ë¡œ ë³‘í•©ë¨)
            print(f"ğŸ”¨ Shard ìƒì„± ì¤‘... (í´ë”: {current_form_folder})")
            result = rag_manager.build_shard(shard_pages, form_type=None)

            if not result:
                print(f"âŒ Shard ìƒì„± ì‹¤íŒ¨ (í´ë”: {current_form_folder})")
                continue

            # resultëŠ” (shard_path ë˜ëŠ” shard_index_name, shard_id) íŠœí”Œ
            shard_identifier, shard_id = result

            # shard ìƒì„± ì‹œ manifest ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (staged ìƒíƒœ)
            print("\nğŸ“‹ DB Manifestì— staged ìƒíƒœ ê¸°ë¡ ì¤‘...")
            page_hashes = {p['page_key']: p['page_hash'] for p in new_pages}
            fingerprints = {p['page_key']: p['fingerprint'] for p in new_pages}

            # DBìš© í˜ì´ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            db_pages = [
                {
                    'pdf_filename': p['pdf_filename'],
                    'page_number': p['page_num']
                }
                for p in new_pages
            ]

            manifest.mark_pages_staged(db_pages, shard_id, page_hashes, fingerprints)
            print(f"âœ… DB Manifest ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ staged ìƒíƒœë¡œ ê¸°ë¡\n")

            # shard â†’ base merge
            if auto_merge:
                print("ğŸ”„ Shardë¥¼ baseì— merge ì¤‘...")
                # shard_identifierëŠ” DB ëª¨ë“œì—ì„œëŠ” index_name, íŒŒì¼ ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ê²½ë¡œ
                merge_success = rag_manager.merge_shard(shard_identifier)

                if merge_success:
                    # merge ì„±ê³µ ì‹œ ìƒíƒœ ì „ì´ (staged â†’ merged)
                    print("\nğŸ“‹ DB Manifest ìƒíƒœ ì „ì´ ì¤‘ (staged â†’ merged)...")
                    manifest.mark_pages_merged(db_pages)
                    print(f"âœ… DB Manifest ìƒíƒœ ì „ì´ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ merged ìƒíƒœë¡œ ë³€ê²½\n")
                    
                    # ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ (ë©”ëª¨ë¦¬ì˜ ì´ì „ ì¸ë±ìŠ¤ ê°±ì‹ )
                    print("ğŸ”„ ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ ì¤‘...")
                    rag_manager.reload_index()
                else:
                    print(f"âŒ Shard merge ì‹¤íŒ¨ (í´ë”: {current_form_folder}, staged ìƒíƒœ ìœ ì§€)\n")
                    continue
            else:
                print(f"\nâš ï¸ ìë™ mergeê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                print(f"   ìˆ˜ë™ìœ¼ë¡œ mergeí•˜ë ¤ë©´: rag_manager.merge_shard('{shard_identifier}')\n")
                print(f"   merge í›„ manifest.mark_pages_merged(db_pages)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n")

            # ê²°ê³¼ ìš”ì•½
            print("="*60)
            print(f"ğŸ“Š í´ë” '{current_form_folder}' ë²¡í„° DB êµ¬ì¶• ê²°ê³¼")
            print("="*60)
            print(f"âœ… ì²˜ë¦¬ëœ í˜ì´ì§€: {len(new_pages)}ê°œ")
            print(f"ğŸ“ˆ ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ")
            print(f"ğŸ’¾ ìµœì¢… ë²¡í„° DB ì˜ˆì œ ìˆ˜: {rag_manager.count_examples()}ê°œ")
            if deleted_pages:
                print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€: {len(deleted_pages)}ê°œ")
            print("="*60)
            print()
        except Exception as e:
            print(f"âŒ í´ë” '{current_form_folder}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
        finally:
            # PDF ìºì‹œ ì •ë¦¬
            text_extractor.close_all()


if __name__ == "__main__":
    import sys
    print("ğŸš€ FAISS ë²¡í„° DB êµ¬ì¶• ì‹œì‘\n")

    # ëª…ë ¹ì¤„ ì¸ìë¡œ img í•˜ìœ„ í´ë” í•˜ë‚˜ë§Œ ì§€ì • ê°€ëŠ¥ (ë¯¸ì§€ì • ì‹œ ì „ì²´)
    form_folder = None
    if len(sys.argv) > 1:
        form_folder = sys.argv[1]
        print(f"ğŸ“ ì§€ì •ëœ í´ë”: {form_folder}\n")

    build_faiss_db(
        form_folder=form_folder,
        auto_merge=True,
        text_extraction_method="excel"  # ê¸°ë³¸ê°’ (ì–‘ì‹ì§€ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
    )
    print("\nâœ… ì™„ë£Œ!")
