"""
img í´ë”ì˜ PDF ë°ì´í„°ë¥¼ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ì¦ë¶„ shard + merge êµ¬ì¡°)

img í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ:
- PDF íŒŒì¼ (PyMuPDFë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
- Page*_answer.json (ì •ë‹µ JSON)

íŒŒì¼ì„ ì°¾ì•„ì„œ ë³€ê²½ë¶„ë§Œ shardë¡œ ìƒì„±í•˜ê³  base DBì— mergeí•©ë‹ˆë‹¤.
"""

import os
import io
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import fitz  # PyMuPDF

from modules.core.rag_manager import get_rag_manager
from modules.utils.config import get_project_root, get_extraction_method_for_upload_channel, folder_name_to_upload_channel
from modules.utils.hash_utils import compute_page_hash, get_page_key, compute_file_fingerprint
from modules.utils.db_manifest_manager import DBManifestManager
from modules.utils.pdf_utils import PdfTextExtractor


def _log(msg: str) -> None:
    """å†æ§‹ç¯‰ãŒAPIçµŒç”±ã§ã‚¹ãƒ¬ãƒƒãƒ‰å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã§ã‚‚ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«å³è¡¨ç¤ºã™ã‚‹ãŸã‚ flush ã™ã‚‹"""
    print(msg, flush=True)


def find_pdf_pages(
    img_dir: Path,
    form_folder: Optional[str] = None,
) -> List[Dict[str, Any]]:
    """
    img í´ë”ì˜ í•˜ìœ„ í´ë”(finet, mail, 01, 02 ë“±) ì•ˆì—ì„œ PDF í˜ì´ì§€ ë°ì´í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        img_dir: img í´ë” ê²½ë¡œ
        form_folder: í•˜ìœ„ í´ë”ëª… (ì˜ˆ: "finet", "mail"). Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë”ë¥¼ ìˆœíšŒ

    Returns:
        [page_data, ...] ë¦¬ìŠ¤íŠ¸
        page_data = {
            'pdf_name': str,
            'page_num': int,
            'pdf_path': Path,
            'answer_json_path': Optional[Path],
            'form_type': Optional[str],  # 01, 02, 03 ë“± ì–‘ì‹ ì½”ë“œ (ìˆìœ¼ë©´)
        }
    """
    pages = []

    # img í•˜ìœ„ í´ë” ëª©ë¡ (finet, mail ë“± ì±„ë„ë³„ ë˜ëŠ” 01, 02 ë“± - ëª¨ë‘ ëŒ€ìƒ)
    if form_folder:
        form_folders = [img_dir / form_folder]
    else:
        form_folders = sorted(
            [d for d in img_dir.iterdir() if d.is_dir() and not d.name.startswith(".")],
            key=lambda d: d.name,
        )

    for form_dir in form_folders:
        if not form_dir.exists():
            continue

        _log(f"ğŸ“ í´ë”: {form_dir.name}")

        # ìƒìœ„ í´ë” ê¸°ì¤€ form_type í›„ë³´ (ê³¼ê±° êµ¬ì¡°: img/01/...)
        parent_form_type: Optional[str] = form_dir.name if form_dir.name.isdigit() else None

        # ê²€ìƒ‰ ë£¨íŠ¸ ê²°ì •: base > íƒ€ì…(01,02) í•˜ìœ„ > ì±„ë„ ì§í•˜ìœ„
        base_dir = form_dir / "base"
        if base_dir.exists() and base_dir.is_dir():
            search_dirs = [base_dir]
        else:
            first_children = [d for d in form_dir.iterdir() if d.is_dir() and not d.name.startswith(".")]
            # ìˆ«ì í´ë”(01~05)ë§Œ ìˆìœ¼ë©´ mail/02, mail/03 ë“± ì–‘ì‹ë³„ í•˜ìœ„ â†’ ë°˜ë“œì‹œ 02,03,04,05 ê°ê° ìŠ¤ìº”
            all_digit_children = first_children and all(d.name.isdigit() for d in first_children)
            if all_digit_children:
                search_dirs = list(first_children)
            else:
                # ì§í•˜ìœ„ì— "í´ë”ëª….pdf"ê°€ ìˆìœ¼ë©´ PDF í´ë”ê°€ ì§í•˜ìœ„ì— ìˆëŠ” êµ¬ì¡° (finet ë“±)
                has_direct_pdf = any((d / f"{d.name}.pdf").exists() for d in first_children)
                if has_direct_pdf:
                    search_dirs = [form_dir]
                else:
                    search_dirs = list(first_children)

        for search_dir in search_dirs:
            # finet/01, mail/02 ë“±ì¼ ë•Œ í˜„ì¬ search_dirì´ ì–‘ì‹ ì½”ë“œ(01~05)ë¥¼ ë‚˜íƒ€ëƒ„
            current_form_type: Optional[str] = None
            if search_dir.name.isdigit():
                current_form_type = search_dir.name
                _log(f"  â–¶ ì–‘ì‹ {search_dir.name} ìŠ¤ìº” ì¤‘...")
            elif parent_form_type:
                # search_dirê°€ base/ë…„-ì›”/ ë“±ì˜ í•˜ìœ„ì¼ ë•Œ ìƒìœ„ í´ë”ëª…ì„ form_typeìœ¼ë¡œ ì‚¬ìš©
                current_form_type = parent_form_type

            # PDF í´ë”ë“¤ ìˆœíšŒ
            for pdf_folder in search_dir.iterdir():
                if not pdf_folder.is_dir() or pdf_folder.name == ".DS_Store":
                    continue

                pdf_name = pdf_folder.name
                pdf_file = pdf_folder / f"{pdf_name}.pdf"
                if not pdf_file.exists():
                    pdf_file = search_dir / f"{pdf_name}.pdf"

                if not pdf_file.exists():
                    print(f"  âš ï¸ PDF íŒŒì¼ ì—†ìŒ: {pdf_name}")
                    continue

                # ë²„ì „ êµ¬ë¶„ ì—†ì´ ëª¨ë“  Page*_answer*.json ëŒ€ìƒìœ¼ë¡œ ì²˜ë¦¬
                answer_files = sorted(pdf_folder.glob("Page*_answer*.json"))

                if not answer_files:
                    print(f"  âš ï¸ {pdf_name}: answer.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                    continue

                try:
                    doc = fitz.open(pdf_file)
                    page_count = len(doc)
                    doc.close()
                except Exception as e:
                    print(f"  âš ï¸ PDF íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨ ({pdf_name}): {e}")
                    continue

                _log(f"  - {pdf_name}: {len(answer_files)}ê°œ answer.json íŒŒì¼, {page_count}í˜ì´ì§€")

                for answer_file in answer_files:
                    try:
                        stem = answer_file.stem
                        import re
                        match = re.match(r'Page(\d+)_answer', stem)
                        if not match:
                            print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                            continue
                        page_num = int(match.group(1))

                        if page_num < 1 or page_num > page_count:
                            print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ ë²”ìœ„ ì´ˆê³¼: {pdf_name} Page{page_num} (ìµœëŒ€: {page_count})")
                            continue

                        pages.append({
                            'pdf_name': pdf_name,
                            'page_num': page_num,
                            'pdf_path': pdf_file,
                            'answer_json_path': answer_file,
                            'form_type': current_form_type,
                        })
                    except ValueError:
                        print(f"  âš ï¸ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨: {answer_file}")
                        continue

    return pages




def load_answer_json(answer_path: Optional[Path]) -> Dict[str, Any]:
    """ì •ë‹µ JSON íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤."""
    if answer_path is None or not answer_path.exists():
        return {}

    try:
        with open(answer_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ ì •ë‹µ JSON ì½ê¸° ì‹¤íŒ¨ ({answer_path}): {e}")
        return {}


def _image_path_for_page(answer_json_path: Optional[Path], page_num: int) -> Optional[Path]:
    """answer.json ã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã® Page{N}.png ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚"""
    if not answer_json_path or not answer_json_path.parent.exists():
        return None
    p = answer_json_path.parent / f"Page{page_num}.png"
    return p if p.exists() else None


def sync_img_pages_to_documents_db(
    db,
    pages: List[Dict[str, Any]],
    upload_channel: str,
    form_folder: str,
) -> None:
    """
    img í´ë”ì—ì„œ ë°œê²¬í•œ ë¬¸ì„œÂ·í˜ì´ì§€ë¥¼ documents_current / page_data_current ã«åæ˜ ã—ã€
    ã•ã‚‰ã« page_metaãƒ»items_currentãƒ»page_images_current ã«ã‚‚åŒæœŸã™ã‚‹ã€‚
    - ç”»åƒ: img å†…ã® Page{N}.png ã‚’ static/images ã«ã‚³ãƒ”ãƒ¼ã— page_images_current ã«ç™»éŒ²
    - æ­£è§£è¡¨: answer.json ã® items ã‚’ items_current ã«ç™»éŒ²ã€page_meta ã‚‚ä¿å­˜
    """
    if not pages:
        return
    try:
        from PIL import Image

        doc_info: Dict[str, Dict[str, Any]] = {}
        for p in pages:
            pdf_name = p.get("pdf_name") or ""
            page_num = p.get("page_num") or 0
            pdf_filename = f"{pdf_name}.pdf" if not pdf_name.endswith(".pdf") else pdf_name
            if pdf_filename not in doc_info:
                doc_info[pdf_filename] = {
                    "total_pages": page_num,
                    "form_type": p.get("form_type") or (form_folder if form_folder.isdigit() else None),
                }
            if page_num > doc_info[pdf_filename]["total_pages"]:
                doc_info[pdf_filename]["total_pages"] = page_num
        form_type_default = form_folder if form_folder.isdigit() else None

        with db.get_connection() as conn:
            cursor = conn.cursor()
            for pdf_filename, info in doc_info.items():
                total_pages = info["total_pages"]
                form_type = info["form_type"] or form_type_default
                cursor.execute(
                    """
                    INSERT INTO documents_current (pdf_filename, form_type, upload_channel, total_pages, updated_at)
                    VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
                    ON CONFLICT (pdf_filename) DO UPDATE SET
                        form_type = COALESCE(EXCLUDED.form_type, documents_current.form_type),
                        upload_channel = COALESCE(EXCLUDED.upload_channel, documents_current.upload_channel),
                        total_pages = GREATEST(documents_current.total_pages, EXCLUDED.total_pages),
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    (pdf_filename, form_type, upload_channel, total_pages),
                )
            conn.commit()

            for pdf_filename in doc_info:
                cursor.execute("DELETE FROM items_current WHERE pdf_filename = %s", (pdf_filename,))
                cursor.execute("DELETE FROM page_images_current WHERE pdf_filename = %s", (pdf_filename,))
            conn.commit()

            for p in pages:
                pdf_name = p.get("pdf_name") or ""
                page_num = p.get("page_num") or 0
                pdf_filename = f"{pdf_name}.pdf" if not pdf_name.endswith(".pdf") else pdf_name
                answer_path = p.get("answer_json_path")
                answer_json = load_answer_json(answer_path)
                page_role = (answer_json.get("page_role") or "detail").strip() or "detail"
                page_meta = {k: v for k, v in answer_json.items() if k not in ("items", "page_role") and v is not None}
                page_meta_json = json.dumps(page_meta, ensure_ascii=False) if page_meta else None

                cursor.execute(
                    """
                    INSERT INTO page_data_current (pdf_filename, page_number, page_role, page_meta, is_rag_candidate, updated_at)
                    VALUES (%s, %s, %s, %s::jsonb, TRUE, CURRENT_TIMESTAMP)
                    ON CONFLICT (pdf_filename, page_number) DO UPDATE SET
                        page_role = COALESCE(EXCLUDED.page_role, page_data_current.page_role),
                        page_meta = COALESCE(EXCLUDED.page_meta, page_data_current.page_meta),
                        is_rag_candidate = TRUE,
                        updated_at = CURRENT_TIMESTAMP
                    """,
                    (pdf_filename, page_num, page_role, page_meta_json),
                )

                items = answer_json.get("items") or []
                if isinstance(items, list):
                    for item_order, item_dict in enumerate(items, 1):
                        if not isinstance(item_dict, dict):
                            continue
                        separated = db._separate_item_fields(item_dict, form_type=form_type_default)
                        cursor.execute(
                            """
                            INSERT INTO items_current (
                                pdf_filename, page_number, item_order,
                                first_review_checked, second_review_checked,
                                first_reviewed_at, second_reviewed_at,
                                item_data
                            )
                            VALUES (%s, %s, %s, %s, %s, %s, %s, %s::jsonb)
                            """,
                            (
                                pdf_filename,
                                page_num,
                                item_order,
                                separated.get("first_review_checked", False),
                                separated.get("second_review_checked", False),
                                separated.get("first_reviewed_at"),
                                separated.get("second_reviewed_at"),
                                json.dumps(separated.get("item_data", {}), ensure_ascii=False),
                            ),
                        )

                img_path = _image_path_for_page(answer_path, page_num)
                if img_path and img_path.exists():
                    try:
                        with Image.open(img_path) as pil_img:
                            if pil_img.mode != "RGB":
                                pil_img = pil_img.convert("RGB")
                            jpeg_buf = io.BytesIO()
                            pil_img.save(jpeg_buf, format="JPEG", quality=95, optimize=True)
                            image_data = jpeg_buf.getvalue()
                        saved_path = db.save_image_to_file(pdf_filename, page_num, image_data)
                        cursor.execute(
                            """
                            INSERT INTO page_images_current
                            (pdf_filename, page_number, image_path, image_format, image_size)
                            VALUES (%s, %s, %s, %s, %s)
                            ON CONFLICT (pdf_filename, page_number) DO UPDATE SET
                                image_path = EXCLUDED.image_path,
                                image_format = EXCLUDED.image_format,
                                image_size = EXCLUDED.image_size,
                                created_at = CURRENT_TIMESTAMP
                            """,
                            (pdf_filename, page_num, saved_path, "JPEG", len(image_data)),
                        )
                    except Exception as img_err:
                        print(f"âš ï¸ ç”»åƒç™»éŒ²ã‚¹ã‚­ãƒƒãƒ— ({pdf_filename} p.{page_num}): {img_err}")

            conn.commit()
        _log(f"âœ… [DBåŒæœŸ] ãƒ•ã‚©ãƒ«ãƒ€ '{form_folder}': {len(doc_info)}æ–‡æ›¸, {len(pages)}ãƒšãƒ¼ã‚¸ â†’ documents / page_data / items / page_images ã«åæ˜ æ¸ˆã¿\n")
    except Exception as e:
        import traceback
        print(f"âš ï¸ DBåŒæœŸä¸­ã«ã‚¨ãƒ©ãƒ¼ (ç¶šè¡Œ): {e}\n")
        traceback.print_exc()


def diff_pages_with_manifest(
    pages: List[Dict[str, Any]],
    manifest: DBManifestManager,
    text_extractor: PdfTextExtractor,
    text_extraction_method: str = "pymupdf"  # "pymupdf" ë˜ëŠ” "excel"
) -> List[Dict[str, Any]]:
    """
    manifestì™€ ë¹„êµí•˜ì—¬ ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    2ë‹¨ê³„ ì²´í¬: 1ë‹¨ê³„(answer.json fingerprint) â†’ 2ë‹¨ê³„(ì‹¤ì œ í…ìŠ¤íŠ¸ hash)
    staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ.

    Args:
        pages: í˜ì´ì§€ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        manifest: DBManifestManager ì¸ìŠ¤í„´ìŠ¤
        text_extractor: PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° (ìºì‹± ì§€ì›)

    Returns:
        ìƒˆë¡œìš´ í˜ì´ì§€ ë˜ëŠ” ë³€ê²½ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
    """
    new_pages = []

    for page_data in pages:
        pdf_name = page_data['pdf_name']
        page_num = page_data['page_num']
        pdf_path = page_data['pdf_path']
        answer_path = page_data.get('answer_json_path')

        if not answer_path or not answer_path.exists():
            continue

        pdf_filename = f"{pdf_name}.pdf"  # DBëŠ” í™•ì¥ì í¬í•¨
        page_key = get_page_key(pdf_name, page_num)

        # staged ìƒíƒœëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        if manifest.is_staged(pdf_filename, page_num):
            continue

        # 1ë‹¨ê³„: answer.json fingerprint ì²´í¬
        fingerprint = compute_file_fingerprint(pdf_path, answer_path)
        if not manifest.is_file_changed_fast(pdf_filename, page_num, fingerprint):
            continue

        # 2ë‹¨ê³„: ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° hash ê³„ì‚°
        # text_extractor.extract_text()ê°€ methodì— ë”°ë¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        # "excel" ë°©ë²•ì€ pdfplumberë¡œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•¨ (í…Œì´ë¸”ë§Œì´ ì•„ë‹˜)
        ocr_text = text_extractor.extract_text(pdf_path, page_num)

        if not ocr_text:
            continue

        answer_json = load_answer_json(answer_path)
        if not answer_json:
            continue

        page_hash = compute_page_hash(ocr_text, answer_json)

        # merged ìƒíƒœì´ê³  hash ë™ì¼í•˜ë©´ ìŠ¤í‚µ
        if manifest.is_processed(pdf_filename, page_num, page_hash):
            continue

        # ìƒˆë¡œìš´ í˜ì´ì§€ì´ê±°ë‚˜ ë³€ê²½ë¨
        new_pages.append({
            **page_data,
            'ocr_text': ocr_text,
            'answer_json': answer_json,
            'page_hash': page_hash,
            'page_key': page_key,
            'fingerprint': fingerprint,
            'pdf_filename': pdf_filename  # DBìš© íŒŒì¼ëª… ì¶”ê°€
        })

    return new_pages


def detect_deleted_pages(
    scanned_pages: List[Dict[str, Any]],  # [{'pdf_name': str, 'page_num': int}, ...]
    manifest: DBManifestManager
) -> List[Dict[str, Any]]:
    """
    ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ (manifestì— ìˆì§€ë§Œ ìŠ¤ìº” ê²°ê³¼ì— ì—†ìŒ).
    í˜„ì¬ í´ë” ìŠ¤ìº”ì— ë“±ì¥í•œ PDFë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨ (ë‹¤ë¥¸ í´ë” ë¬¸ì„œëŠ” ì‚­ì œë¡œ ì˜¤ì¸í•˜ì§€ ì•ŠìŒ).
    """
    scanned_set = {
        (f"{p['pdf_name']}.pdf", p['page_num'])
        for p in scanned_pages
    }
    # ì´ë²ˆ í´ë” ìŠ¤ìº”ì— ë‚˜ì˜¨ PDFë§Œ ì‚­ì œ í›„ë³´ë¡œ í•œì • (finet/mail ë“± ë‹¤ë¥¸ í´ë” í˜ì´ì§€ ì œì™¸)
    current_folder_pdfs = {f"{p['pdf_name']}.pdf" for p in scanned_pages}

    try:
        with manifest.db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT pdf_filename, page_number, status
                FROM rag_learning_status_current
                WHERE status IN ('merged', 'staged')
            """)

            deleted_pages = []
            for row in cursor.fetchall():
                pdf_filename = row[0]
                page_number = row[1]
                if pdf_filename not in current_folder_pdfs:
                    continue
                if (pdf_filename, page_number) not in scanned_set:
                    deleted_pages.append({
                        'pdf_filename': pdf_filename,
                        'page_number': page_number
                    })

        return deleted_pages
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        print(f"âš ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        return []


def build_faiss_db(
    img_dir: Path = None,
    form_folder: Optional[str] = None,
    auto_merge: bool = False,
    text_extraction_method: str = "pymupdf"  # ê¸°ë³¸ê°’ (ì–‘ì‹ì§€ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œ ì‚¬ìš©)
) -> None:
    """
    img í´ë” í•˜ìœ„(finet, mail ë“±)ë¥¼ ìŠ¤ìº”í•˜ì—¬ FAISS ë²¡í„° DBë¡œ ë³€í™˜í•©ë‹ˆë‹¤ (ì¦ë¶„ shard + ë‹¨ì¼ ê¸€ë¡œë²Œ base).

    Args:
        img_dir: img í´ë” ê²½ë¡œ (Noneì´ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸/img)
        form_folder: í•˜ìœ„ í´ë”ëª… í•˜ë‚˜ë§Œ ì§€ì • (ì˜ˆ: "finet"). Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë” ìˆœíšŒ
        auto_merge: shard ìƒì„± í›„ baseì— ìë™ merge ì—¬ë¶€
        text_extraction_method: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ê¸°ë³¸ê°’ (config.form_extraction_methodì— ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    """
    if img_dir is None:
        project_root = get_project_root()
        img_dir = project_root / "img"

    if not img_dir.exists():
        print(f"âŒ img í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_dir}")
        return

    # RAG Manager ì´ˆê¸°í™”
    print("ğŸ”„ RAG Manager ì´ˆê¸°í™” ì¤‘...")
    try:
        rag_manager = get_rag_manager()
        # ë²¡í„°DBê°€ ì‚­ì œ í›„ ì¬ìƒì„±ëœ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ
        print("ğŸ”„ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ ì¤‘ (ìµœì‹  ìƒíƒœ í™•ì¸)...")
        rag_manager.reload_index()
        print("âœ… RAG Manager ì´ˆê¸°í™” ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ RAG Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # DB Manifest Manager ì´ˆê¸°í™”
    manifest = DBManifestManager()

    print(f"ğŸ“‹ DB Manifest ë¡œë“œ: {len(manifest.get_all_page_keys())}ê°œ í˜ì´ì§€ ë“±ë¡ë¨\n")

    # form_folderê°€ Noneì´ë©´ img í•˜ìœ„ ëª¨ë“  í´ë”(finet, mail ë“±) ìˆœíšŒ
    if form_folder:
        form_folders_to_process = [form_folder]
    else:
        form_folders_to_process = sorted(
            d.name for d in img_dir.iterdir()
            if d.is_dir() and not d.name.startswith(".")
        )

    # img í•˜ìœ„ ê° í´ë”(finet, mail ë“±) ì²˜ë¦¬
    for current_form_folder in form_folders_to_process:
        _log(f"\n{'='*60}")
        _log(f"ğŸ“‚ í´ë” '{current_form_folder}' ì²˜ë¦¬ ì¤‘")
        _log(f"{'='*60}\n")

        # í´ë”ëª…ì„ upload_channelë¡œ ë³€í™˜ (form_type â†’ upload_channel ë§¤í•‘)
        upload_channel = folder_name_to_upload_channel(current_form_folder)
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• ê²°ì • (upload_channel ê¸°ë°˜)
        extraction_method = get_extraction_method_for_upload_channel(upload_channel)
        if extraction_method == text_extraction_method:
            pass
        _log(f"ğŸ“ '{current_form_folder}' â†’ upload_channel: {upload_channel}, ì¶”ì¶œ ë°©ë²•: {extraction_method}\n")

        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„± (ìºì‹± ì§€ì›)
        text_extractor = PdfTextExtractor(method=extraction_method, upload_channel=upload_channel)

        pages = find_pdf_pages(img_dir, current_form_folder)
        if not pages:
            _log(f"âš ï¸ í´ë” '{current_form_folder}'ì— ì²˜ë¦¬í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
            text_extractor.close_all()  # ìºì‹œ ì •ë¦¬
            continue

        _log(f"âœ… {len(pages)}ê°œ í˜ì´ì§€ ë°œê²¬\n")

        # img ç”±æ¥ã®æ–‡æ›¸ãƒ»ãƒšãƒ¼ã‚¸ã‚’ DB ã«åŒæœŸã—ã€ç¾æ³ã®æ–‡æ›¸ä¸€è¦§ã«è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
        if getattr(rag_manager, "db", None):
            sync_img_pages_to_documents_db(rag_manager.db, pages, upload_channel, current_form_folder)
        else:
            _log("âš ï¸ DB æœªæ¥ç¶šã®ãŸã‚ã€æ–‡æ›¸ä¸€è¦§ï¼ˆç¾æ³ï¼‰ã«ã¯åæ˜ ã•ã‚Œã¾ã›ã‚“ã€‚\n")

        try:
            # ì‚­ì œëœ í˜ì´ì§€ ê°ì§€
            deleted_pages = detect_deleted_pages(pages, manifest)
            if deleted_pages:
                print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€ ê°ì§€: {len(deleted_pages)}ê°œ")
                for deleted in deleted_pages[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                    print(f"   - {deleted['pdf_filename']} í˜ì´ì§€ {deleted['page_number']}")
                if len(deleted_pages) > 10:
                    print(f"   ... ì™¸ {len(deleted_pages) - 10}ê°œ")
                manifest.mark_pages_deleted(deleted_pages)

            # manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ë§Œ í•„í„°ë§
            print(f"ğŸ” Manifestì™€ ë¹„êµí•˜ì—¬ ë³€ê²½ë¶„ í™•ì¸ ì¤‘... (í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²•: {extraction_method})")
            new_pages = diff_pages_with_manifest(pages, manifest, text_extractor, extraction_method)
            print(f"   ìŠ¤ìº” {len(pages)}ê°œ â†’ ë³€ê²½ë¶„ {len(new_pages)}ê°œ")

            if not new_pages:
                print(f"âœ… í´ë” '{current_form_folder}': ë³€ê²½ëœ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                # ë³€ê²½ ì—†ì–´ë„ ë²¡í„° DB êµ¬ì¶• ê²°ê³¼ ìš”ì•½ì€ ë™ì¼ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (mail ë“± ëˆ„ë½ ì˜¤í•´ ë°©ì§€)
                existing_count = rag_manager.count_examples()
                print("="*60)
                print(f"ğŸ“Š í´ë” '{current_form_folder}' ë²¡í„° DB êµ¬ì¶• ê²°ê³¼")
                print("="*60)
                print(f"âœ… ì²˜ë¦¬ëœ í˜ì´ì§€: 0ê°œ (ë³€ê²½ ì—†ìŒ)")
                print(f"ğŸ“ˆ ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ")
                print(f"ğŸ’¾ ìµœì¢… ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ")
                if deleted_pages:
                    print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€: {len(deleted_pages)}ê°œ")
                print("="*60)
                print()
                continue

            print(f"ğŸ“ ë³€ê²½ëœ í˜ì´ì§€: {len(new_pages)}ê°œ ë°œê²¬\n")

            # ê¸°ì¡´ ì˜ˆì œ ìˆ˜ í™•ì¸ (ì–‘ì‹ì§€ë³„)
            # TODO: count_examplesë„ form_typeë³„ë¡œ ì¹´ìš´íŠ¸í•˜ë„ë¡ ìˆ˜ì • í•„ìš”
            existing_count = rag_manager.count_examples()
            print(f"ğŸ“Š ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ\n")

            # shard ìƒì„±ì„ ìœ„í•œ í˜ì´ì§€ ë°ì´í„° ì¤€ë¹„
            shard_pages = []
            for page_data in new_pages:
                pdf_name = page_data['pdf_name']
                page_num = page_data['page_num']
                # í˜ì´ì§€ ë‹¨ìœ„ form_type (01~05 ë“±)ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í´ë”ëª… ê·¸ëŒ€ë¡œ
                page_form_type = page_data.get('form_type') or current_form_folder

                metadata = {
                    'pdf_name': pdf_name,
                    'page_num': page_num,
                    # upload_channel(finet/mail)ê³¼ form_type(01~05)ì„ ëª¨ë‘ ë©”íƒ€ë°ì´í„°ì— ì €ì¥
                    'upload_channel': upload_channel,
                    'form_type': page_form_type,
                    'source': 'img_folder'
                }

                shard_pages.append({
                    'pdf_name': pdf_name,
                    'page_num': page_num,
                    'ocr_text': page_data['ocr_text'],
                    'answer_json': page_data['answer_json'],
                    'metadata': metadata,
                    'page_key': page_data['page_key'],
                    'page_hash': page_data['page_hash']
                })

            # shard FAISS DB ìƒì„± (ë‹¨ì¼ ê¸€ë¡œë²Œ ì¸ë±ìŠ¤ë¡œ ë³‘í•©ë¨)
            print(f"ğŸ”¨ Shard ìƒì„± ì¤‘... (í´ë”: {current_form_folder})")
            result = rag_manager.build_shard(shard_pages, form_type=None)

            if not result:
                print(f"âŒ Shard ìƒì„± ì‹¤íŒ¨ (í´ë”: {current_form_folder})")
                continue

            # resultëŠ” (shard_path ë˜ëŠ” shard_index_name, shard_id) íŠœí”Œ
            shard_identifier, shard_id = result

            # shard ìƒì„± ì‹œ manifest ì¦‰ì‹œ ì—…ë°ì´íŠ¸ (staged ìƒíƒœ)
            print("\nğŸ“‹ DB Manifestì— staged ìƒíƒœ ê¸°ë¡ ì¤‘...")
            page_hashes = {p['page_key']: p['page_hash'] for p in new_pages}
            fingerprints = {p['page_key']: p['fingerprint'] for p in new_pages}

            # DBìš© í˜ì´ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            db_pages = [
                {
                    'pdf_filename': p['pdf_filename'],
                    'page_number': p['page_num']
                }
                for p in new_pages
            ]

            manifest.mark_pages_staged(db_pages, shard_id, page_hashes, fingerprints)
            print(f"âœ… DB Manifest ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ staged ìƒíƒœë¡œ ê¸°ë¡\n")

            # shard â†’ base merge
            if auto_merge:
                print("ğŸ”„ Shardë¥¼ baseì— merge ì¤‘...")
                # shard_identifierëŠ” DB ëª¨ë“œì—ì„œëŠ” index_name, íŒŒì¼ ëª¨ë“œì—ì„œëŠ” íŒŒì¼ ê²½ë¡œ
                merge_success = rag_manager.merge_shard(shard_identifier)

                if merge_success:
                    # merge ì„±ê³µ ì‹œ ìƒíƒœ ì „ì´ (staged â†’ merged)
                    print("\nğŸ“‹ DB Manifest ìƒíƒœ ì „ì´ ì¤‘ (staged â†’ merged)...")
                    manifest.mark_pages_merged(db_pages)
                    print(f"âœ… DB Manifest ìƒíƒœ ì „ì´ ì™„ë£Œ: {len(db_pages)}ê°œ í˜ì´ì§€ merged ìƒíƒœë¡œ ë³€ê²½\n")
                    
                    # ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ (ë©”ëª¨ë¦¬ì˜ ì´ì „ ì¸ë±ìŠ¤ ê°±ì‹ )
                    print("ğŸ”„ ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤ ë¦¬ë¡œë“œ ì¤‘...")
                    rag_manager.reload_index()
                else:
                    print(f"âŒ Shard merge ì‹¤íŒ¨ (í´ë”: {current_form_folder}, staged ìƒíƒœ ìœ ì§€)\n")
                    continue
            else:
                print(f"\nâš ï¸ ìë™ mergeê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                print(f"   ìˆ˜ë™ìœ¼ë¡œ mergeí•˜ë ¤ë©´: rag_manager.merge_shard('{shard_identifier}')\n")
                print(f"   merge í›„ manifest.mark_pages_merged(db_pages)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n")

            # ê²°ê³¼ ìš”ì•½
            print("="*60)
            print(f"ğŸ“Š í´ë” '{current_form_folder}' ë²¡í„° DB êµ¬ì¶• ê²°ê³¼")
            print("="*60)
            print(f"âœ… ì²˜ë¦¬ëœ í˜ì´ì§€: {len(new_pages)}ê°œ")
            print(f"ğŸ“ˆ ê¸°ì¡´ ë²¡í„° DB ì˜ˆì œ ìˆ˜: {existing_count}ê°œ")
            print(f"ğŸ’¾ ìµœì¢… ë²¡í„° DB ì˜ˆì œ ìˆ˜: {rag_manager.count_examples()}ê°œ")
            if deleted_pages:
                print(f"ğŸ—‘ï¸ ì‚­ì œëœ í˜ì´ì§€: {len(deleted_pages)}ê°œ")
            print("="*60)
            print()
        except Exception as e:
            print(f"âŒ í´ë” '{current_form_folder}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            continue
        finally:
            # PDF ìºì‹œ ì •ë¦¬
            text_extractor.close_all()


if __name__ == "__main__":
    import sys
    print("ğŸš€ FAISS ë²¡í„° DB êµ¬ì¶• ì‹œì‘\n")

    # ëª…ë ¹ì¤„ ì¸ìë¡œ img í•˜ìœ„ í´ë” í•˜ë‚˜ë§Œ ì§€ì • ê°€ëŠ¥ (ë¯¸ì§€ì • ì‹œ ì „ì²´)
    form_folder = None
    if len(sys.argv) > 1:
        form_folder = sys.argv[1]
        print(f"ğŸ“ ì§€ì •ëœ í´ë”: {form_folder}\n")

    build_faiss_db(
        form_folder=form_folder,
        auto_merge=True,
        text_extraction_method="excel"  # ê¸°ë³¸ê°’ (ì–‘ì‹ì§€ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
    )
    print("\nâœ… ì™„ë£Œ!")
