"""
ê²€ìƒ‰ API
"""
import asyncio
import json
from pathlib import Path
from typing import List, Optional

import pandas as pd
from urllib.parse import quote
from fastapi import APIRouter, HTTPException, Depends, Query, Body
from pydantic import BaseModel

from database.registry import get_db
from database.db_manager import _similarity_difflib
from backend.core.auth import get_current_user_optional, get_current_user
from backend.unit_price_lookup import split_name_and_capacity, find_similar_products

router = APIRouter()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (search.py: backend/api/routes/search.py -> parent*4 = project_root)
_PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent.parent
_UNIT_PRICE_CSV = _PROJECT_ROOT / "database" / "csv" / "unit_price.csv"


def _get_in_vector_pdf_filenames(db) -> List[str]:
    """rag_vector_indexì—ì„œ ë²¡í„° ì¸ë±ìŠ¤ì— í¬í•¨ëœ pdf_filename ëª©ë¡ ë°˜í™˜."""
    try:
        with db.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT metadata_json FROM rag_vector_index
                WHERE index_name = 'base' AND (form_type IS NULL OR form_type = '')
                ORDER BY updated_at DESC LIMIT 1
            """)
            row = cursor.fetchone()
        if not row:
            return []
        meta = row[0]
        if meta is None:
            return []
        if isinstance(meta, str):
            try:
                meta = json.loads(meta)
            except Exception:
                return []
        if not isinstance(meta, dict):
            return []
        metadata_dict = meta.get("metadata") or meta.get("Metadata") or {}
        pdf_names = set()
        for _doc_id, doc_data in (metadata_dict or {}).items():
            if not isinstance(doc_data, dict):
                continue
            inner = doc_data.get("metadata") or doc_data.get("Metadata") or {}
            pn = (inner or {}).get("pdf_name") or (inner or {}).get("pdf_filename")
            if pn:
                pdf_names.add(pn)
        return [
            p if (p and str(p).lower().endswith(".pdf")) else f"{p}.pdf"
            for p in pdf_names
        ]
    except Exception:
        return []


class PagesByCustomersRequest(BaseModel):
    customer_names: List[str]
    form_type: Optional[str] = None


class CustomerSimilarityMappingRequest(BaseModel):
    """ê±°ë˜ì²˜(ì™¼ìª½) vs ë‹´ë‹¹(ì˜¤ë¥¸ìª½) ìœ ì‚¬ë„ ë§¤í•‘ ìš”ì²­. notepad find_similar_supersì™€ ë™ì¼í•œ difflib ì‚¬ìš©."""
    customer_names: List[str]
    super_names: List[str]


@router.get("/customer")
async def search_by_customer(
    customer_name: str = Query(..., description="ê±°ë˜ì²˜ëª…"),
    exact_match: bool = Query(False, description="ì™„ì „ ì¼ì¹˜ ì—¬ë¶€"),
    form_type: Optional[str] = Query(None, description="ì–‘ì‹ì§€ íƒ€ì… í•„í„°"),
    my_supers_only: bool = Query(False, description="ë¡œê·¸ì¸ ì‚¬ìš©ì ë‹´ë‹¹ ìŠˆí¼ë§Œ (ìœ ì‚¬ë„ 90% ì´ìƒ)"),
    db=Depends(get_db),
    current_user=Depends(get_current_user_optional),
):
    """
    ê±°ë˜ì²˜ëª…ìœ¼ë¡œ ê²€ìƒ‰.
    my_supers_only=Trueì´ë©´ ë¡œê·¸ì¸ í•„ìš”, ë‹´ë‹¹ ìŠˆí¼ëª…ê³¼ ìœ ì‚¬ë„ 90% ì´ìƒì¸ í•­ëª©ë§Œ ë°˜í™˜.
    """
    if my_supers_only and not current_user:
        raise HTTPException(status_code=401, detail="ë‚´ ë‹´ë‹¹ë§Œ ë³´ë ¤ë©´ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤")
    super_names: Optional[List[str]] = None
    if my_supers_only and current_user:
        from modules.utils.retail_user_utils import get_super_names_for_username
        super_names = get_super_names_for_username(current_user["username"] or "")
        if not super_names:
            return {"query": customer_name, "total_items": 0, "total_pages": 0, "pages": []}
    try:
        results = db.search_items_by_customer(
            customer_name=customer_name,
            exact_match=exact_match,
            form_type=form_type,
            super_names=super_names,
            min_similarity=0.9,
        )
        print(f"ğŸ” [search/customer] query={customer_name!r}, my_supers_only={my_supers_only}, items ê²°ê³¼={len(results)}ê±´")
        
        # íŒŒì¼ëª…ê³¼ í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™”
        grouped_results = {}
        for item in results:
            pdf_filename = item.get('pdf_filename')
            page_number = item.get('page_number')
            key = (pdf_filename, page_number)
            
            if key not in grouped_results:
                grouped_results[key] = {
                    'pdf_filename': pdf_filename,
                    'page_number': page_number,
                    'items': [],
                    'form_type': item.get('form_type')
                }
            grouped_results[key]['items'].append(item)
        
        # items ê²€ìƒ‰ ê²°ê³¼ê°€ 0ì´ë©´ page_data.page_meta(JSON í…ìŠ¤íŠ¸)ì—ì„œ í´ë°± ê²€ìƒ‰
        if len(results) == 0 and customer_name.strip():
            fallback_pages = db.search_pages_by_customer_in_page_meta(customer_name.strip())
            print(f"ğŸ” [search/customer] items 0ê±´ â†’ page_meta í´ë°± ê²€ìƒ‰: {len(fallback_pages)}í˜ì´ì§€")
            for row in fallback_pages:
                pdf_filename = row.get('pdf_filename')
                page_number = row.get('page_number')
                if not pdf_filename or not page_number:
                    continue
                key = (pdf_filename, page_number)
                if key in grouped_results:
                    continue
                page_result = db.get_page_result(pdf_filename, page_number)
                if page_result and page_result.get('items'):
                    grouped_results[key] = {
                        'pdf_filename': pdf_filename,
                        'page_number': page_number,
                        'items': page_result['items'],
                        'form_type': row.get('form_type') or (page_result.get('form_type') if isinstance(page_result.get('form_type'), str) else None)
                    }
        
        total_items = sum(len(g['items']) for g in grouped_results.values())
        return {
            "query": customer_name,
            "total_items": total_items,
            "total_pages": len(grouped_results),
            "pages": list(grouped_results.values())
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/my-supers")
async def get_my_supers(current_user=Depends(get_current_user)):
    """
    ë¡œê·¸ì¸ ì‚¬ìš©ì ë‹´ë‹¹ ê±°ë˜ì²˜(ìŠˆí¼) ëª©ë¡ (retail_user.csv ê¸°ì¤€).
    ê²€í†  íƒ­ì—ì„œ ê±°ë˜ì²˜ ëª©ë¡ ë²„íŠ¼ í´ë¦­ ì‹œ "ë‚´ ë‹´ë‹¹ ê±°ë˜ì²˜" í‘œì‹œìš©.
    """
    from modules.utils.retail_user_utils import get_super_names_for_username
    super_names = get_super_names_for_username(current_user["username"] or "")
    return {"super_names": super_names}


@router.get("/all-super-names")
async def get_all_super_names_route(current_user=Depends(get_current_user)):
    """
    retail_user.csv ëŒ€í‘œìŠˆí¼ëª… ì „ì²´(ì¤‘ë³µ ì œê±°). ê±°ë˜ì²˜â†”ë‹´ë‹¹ ìœ ì‚¬ë„ ë§¤í•‘ ì‹œ notepadì™€ ë™ì¼í•˜ê²Œ ì „ì²´ í’€ì—ì„œ ìµœì  ë§¤ì¹­ìš©.
    """
    from modules.utils.retail_user_utils import get_all_super_names
    return {"super_names": get_all_super_names()}


@router.get("/my-super-pages")
async def get_my_super_pages(
    form_type: Optional[str] = Query(None, description="ì–‘ì‹ì§€ íƒ€ì… í•„í„°"),
    db=Depends(get_db),
    current_user=Depends(get_current_user),
):
    """
    ë¡œê·¸ì¸ ì‚¬ìš©ì ë‹´ë‹¹ ìŠˆí¼(ê±°ë˜ì²˜)ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ì´ ìˆëŠ” í˜ì´ì§€ ëª©ë¡.
    retail_user.csv ê¸°ì¤€, ê²€í†  íƒ­ "ë‚´ ë‹´ë‹¹ë§Œ" í•„í„°ìš© (ìœ ì‚¬ë„ 90% ì´ìƒ).
    """
    from modules.utils.retail_user_utils import get_super_names_for_username
    super_names = get_super_names_for_username(current_user["username"] or "")
    pages = db.get_page_keys_by_super_names(
        super_names=super_names,
        form_type=form_type,
        min_similarity=0.9,
    )
    return {"pages": pages}


@router.get("/review-tab-customers")
async def get_review_tab_customers(
    year: Optional[int] = Query(None, description="ì—°ë„ (ì„ íƒ, ì—†ìœ¼ë©´ ì „ì²´)"),
    month: Optional[int] = Query(None, description="ì›” (ì„ íƒ, ì—†ìœ¼ë©´ ì „ì²´)"),
    db=Depends(get_db),
):
    """
    ê²€í†  íƒ­ì— ìˆëŠ” ëª¨ë“  ê±°ë˜ì²˜ ëª©ë¡ (ì •ë‹µì§€Â·ë²¡í„° ë“±ë¡ ë¬¸ì„œ ì œì™¸, itemsì˜ å¾—æ„å…ˆ/customer ì¤‘ë³µ ì œê±°).
    ê²€í†  íƒ­ì—ì„œ ê±°ë˜ì²˜ ëª©ë¡ ë²„íŠ¼ í´ë¦­ ì‹œ "ê²€í†  íƒ­ ì „ì²´ ê±°ë˜ì²˜" í‘œì‹œìš©.
    """
    in_vector = _get_in_vector_pdf_filenames(db)
    pdfs = db.get_review_tab_pdf_filenames(in_vector, year=year, month=month)
    customer_names = db.get_distinct_customer_names_for_pdfs(pdfs)
    return {"customer_names": customer_names}


@router.post("/pages-by-customers")
async def post_pages_by_customers(
    body: PagesByCustomersRequest,
    db=Depends(get_db),
    current_user=Depends(get_current_user),
):
    """
    ì„ íƒí•œ customerëª… ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ì´ ìˆëŠ” í˜ì´ì§€ ëª©ë¡ ë°˜í™˜ (ì™„ì „ ì¼ì¹˜).
    ëª¨ë‹¬ì—ì„œ ç¢ºèª í›„ í•„í„° ì ìš©ìš©.
    """
    if not body.customer_names:
        return {"pages": []}
    pages = db.get_page_keys_by_customer_names(
        customer_names=body.customer_names,
        form_type=body.form_type,
    )
    return {"pages": pages}


@router.post("/customer-similarity-mapping")
async def post_customer_similarity_mapping(
    body: CustomerSimilarityMappingRequest,
    current_user=Depends(get_current_user),
):
    """
    ì™¼ìª½(ì‹¤ì œ ê±°ë˜ì²˜) ê°ê°ì— ëŒ€í•´ ì˜¤ë¥¸ìª½(ë‹´ë‹¹) ì¤‘ ìœ ì‚¬ë„ ìµœê³ ì¸ 1ê°œ + ì ìˆ˜ ë°˜í™˜.
    notepad.ipynb find_similar_supersì™€ ë™ì¼í•œ difflib ìœ ì‚¬ë„ ì‚¬ìš© (Levenshtein ì•„ë‹˜).
    """
    left_list = [s.strip() for s in (body.customer_names or []) if s is not None]
    right_list = [s.strip() for s in (body.super_names or []) if s is not None]
    used_rights = set()
    mapped: List[dict] = []
    for left in left_list:
        best_right = ""
        best_score = 0.0
        for right in right_list:
            score = _similarity_difflib(left, right)
            if score > best_score:
                best_score = score
                best_right = right
        if best_right:
            used_rights.add(best_right)
        mapped.append({"left": left, "right": best_right, "score": round(best_score, 4)})
    unmapped_rights = [r for r in right_list if r not in used_rights]
    return {"mapped": mapped, "unmapped_rights": unmapped_rights}


@router.get("/unit-price-by-product")
async def get_unit_price_by_product(
    product_name: str = Query(..., description="å•†å“åï¼ˆì œí’ˆëª…ï¼‰"),
    top_k: int = Query(10, ge=1, le=50, description="ë°˜í™˜ ê±´ìˆ˜"),
    min_similarity: float = Query(0.2, ge=0.0, le=1.0, description="ì œí’ˆëª… ìµœì†Œ ìœ ì‚¬ë„"),
    sub_min_similarity: float = Query(0.0, ge=0.0, le=1.0, description="ì œí’ˆìš©ëŸ‰ ìµœì†Œ ìœ ì‚¬ë„"),
):
    """
    ì œí’ˆëª…(å•†å“å)ì„ ì…ë ¥ë°›ì•„ ìš©ëŸ‰ì„ ë¶„ë¦¬í•˜ê³ , unit_price.csvì—ì„œ ì œí’ˆëª…Â·ìš©ëŸ‰ ìœ ì‚¬ë„ë¡œ
    ë§¤ì¹­ëœ ì‹œí‚¤ë¦¬/ë³¸ë¶€ì¥ ë‹¨ê°€ ëª©ë¡ì„ ë°˜í™˜. ê²€í†  íƒ­ì—ì„œ ê·¸ë¦¬ë“œ ì¶”ê°€ìš©.
    """
    if not _UNIT_PRICE_CSV.exists():
        raise HTTPException(status_code=503, detail="unit_price.csv not found")
    try:
        base_name, capacity = split_name_and_capacity(product_name)
        sub_query = capacity if capacity else None
        df = find_similar_products(
            query=base_name,
            csv_path=_UNIT_PRICE_CSV,
            col="ì œí’ˆëª…",
            top_k=top_k,
            min_similarity=min_similarity,
            sub_col="ì œí’ˆìš©ëŸ‰",
            sub_query=sub_query,
            sub_min_similarity=sub_min_similarity,
        )
        # NaN ë“± ì²˜ë¦¬í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        records = []
        for _, row in df.iterrows():
            rec = row.to_dict()
            for k, v in rec.items():
                if hasattr(v, "item") and callable(getattr(v, "item", None)):
                    try:
                        rec[k] = v.item()
                    except (ValueError, AttributeError):
                        rec[k] = None if pd.isna(v) else v
                elif hasattr(v, "__float__") and pd.isna(v):
                    rec[k] = None
                else:
                    rec[k] = v
            records.append(rec)
        return {
            "base_name": base_name,
            "capacity": capacity,
            "product_name_input": product_name,
            "matches": records,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{pdf_filename}/pages/{page_number}/image")
async def get_page_image_url(
    pdf_filename: str,
    page_number: int,
    db=Depends(get_db)
):
    """
    í˜ì´ì§€ ì´ë¯¸ì§€ URL ì¡°íšŒ (page_role ì •ë³´ í¬í•¨)

    Args:
        pdf_filename: PDF íŒŒì¼ëª…
        page_number: í˜ì´ì§€ ë²ˆí˜¸
        db: ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
    """
    try:
        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì¡°íšŒ
        image_path = db.get_page_image_path(pdf_filename, page_number)

        # page_role ì •ë³´ ì¡°íšŒ
        # documents.get_page_meta ì™€ ë™ì¼í•˜ê²Œ db.get_page_result ë¥¼ ì‚¬ìš©í•˜ì—¬
        # current / archive ë“± í…Œì´ë¸” êµ¬ì¡° ë³€ê²½ì— ìƒê´€ì—†ì´ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ page_role ì„ ê°€ì ¸ì˜¨ë‹¤.
        page_role = None
        try:
            page_result = db.get_page_result(pdf_filename, page_number)
            if page_result:
                page_role = page_result.get("page_role")
        except Exception:
            # page_role ì¡°íšŒ ì‹¤íŒ¨ ì‹œ None ìœ ì§€ (ë°°ì§€ ë¹„í‘œì‹œ)
            pass

        if not image_path:
            # ì´ë¯¸ì§€ê°€ ì•„ì§ DBì— ì—†ì–´ë„ 404 ëŒ€ì‹  200 + image_url: null ë°˜í™˜ (ê²€í†  íƒ­ ë“±ì—ì„œ ì—ëŸ¬ ëŒ€ì‹  ì•ˆë‚´ í‘œì‹œ)
            return {
                "image_url": None,
                "format": "jpeg",
                **({"page_role": page_role} if page_role else {}),
            }

        # Windows ë“±ì—ì„œ DBì— ë°±ìŠ¬ë˜ì‹œë¡œ ì €ì¥ëœ ê²½ë¡œë¥¼ URLìš© ìŠ¬ë˜ì‹œë¡œ ì •ê·œí™”
        image_path = image_path.replace("\\", "/")

        # íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¥¼ URL ê²½ë¡œë¡œ ë³€í™˜ ("static/images/..." -> "/static/images/...")
        if image_path.startswith("static/"):
            path_parts = image_path.split("/")
            encoded_parts = [quote(part, safe="") for part in path_parts]
            image_url = "/" + "/".join(encoded_parts)
        elif image_path.startswith("/"):
            path_parts = image_path[1:].split("/")
            encoded_parts = [quote(part, safe="") for part in path_parts]
            image_url = "/" + "/".join(encoded_parts)
        else:
            path_parts = image_path.split("/")
            encoded_parts = [quote(part, safe="") for part in path_parts]
            image_url = "/" + "/".join(encoded_parts)

        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ìƒì„±: {image_path} -> {image_url}")

        response = {
            "image_url": image_url,
            "format": "jpeg"
        }

        # page_roleì´ ìˆìœ¼ë©´ ì‘ë‹µì— í¬í•¨
        if page_role:
            response["page_role"] = page_role

        return response

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/{pdf_filename}/pages/{page_number}/ocr-text")
async def get_page_ocr_text(
    pdf_filename: str,
    page_number: int,
    db=Depends(get_db)
):
    """
    í˜ì´ì§€ OCR í…ìŠ¤íŠ¸ ì¡°íšŒ (ì •ë‹µì§€ ìƒì„± íƒ­ì—ì„œ ì´ë¯¸ì§€ ì•„ë˜ í‘œì‹œìš©)

    1) debug2/{pdf_name}/page_{N}_ocr_text.txt (RAG íŒŒì‹± ì‹œ ì €ì¥ëœ íŒŒì¼)
    2) ì €ì¥ëœ í˜ì´ì§€ ì´ë¯¸ì§€ë¡œ Azure OCR(í‘œ ë³µì›)
    3) PDF ì„¸ì…˜ ê²½ë¡œì—ì„œ Azure(í‘œ ë³µì›) ë˜ëŠ” PyMuPDF ì¶”ì¶œ
    4) result/ í˜ì´ì§€ JSONì˜ text í•„ë“œ ì‹œë„
    """
    try:
        pdf_name = pdf_filename
        if pdf_name.lower().endswith(".pdf"):
            pdf_name = pdf_name[:-4]

        ocr_text = ""

        # 1) debug2/{pdf_name}/page_{N}_ocr_text.txt (RAG íŒŒì‹± ì‹œ ì €ì¥ëœ OCR í…ìŠ¤íŠ¸)
        try:
            from pathlib import Path
            from modules.utils.config import get_project_root

            root = get_project_root()
            debug2_file = root / "debug2" / pdf_name / f"page_{page_number}_ocr_text.txt"
            if debug2_file.exists():
                ocr_text = debug2_file.read_text(encoding="utf-8").strip()
        except Exception:
            pass

        # 2) ì €ì¥ëœ í˜ì´ì§€ ì´ë¯¸ì§€ë¡œ Azure OCR(í‘œ ë³µì›)
        if not ocr_text.strip():
            try:
                image_path = db.get_page_image_path(pdf_filename, page_number)
                if image_path:
                    from pathlib import Path
                    from modules.utils.config import get_project_root
                    from modules.core.extractors.azure_extractor import get_azure_extractor
                    from modules.utils.table_ocr_utils import raw_to_full_text

                    root = get_project_root()
                    full_path = Path(image_path) if Path(image_path).is_absolute() else root / image_path
                    if full_path.exists():
                        extractor = get_azure_extractor(model_id="prebuilt-layout", enable_cache=False)
                        raw = await asyncio.to_thread(
                            extractor.extract_from_image_raw, image_path=full_path
                        )
                        if raw:
                            ocr_text = raw_to_full_text(raw)  # í‘œì‹œìš©: ì¸ì‹í•œ ì „ì²´ ë¬¸ìì—´
            except Exception:
                pass

        # 3) PDF íŒŒì¼ì—ì„œ Azure(í‘œ ë³µì›) ë˜ëŠ” PyMuPDF ì¶”ì¶œ
        if not ocr_text.strip():
            try:
                from pathlib import Path
                from modules.utils.pdf_utils import find_pdf_path, PdfTextExtractor

                pdf_path_str = find_pdf_path(pdf_name)
                if pdf_path_str:
                    def _extract_pdf_text():
                        ext = PdfTextExtractor(upload_channel="mail")
                        try:
                            return ext.extract_text(Path(pdf_path_str), page_number) or ""
                        finally:
                            ext.close_all()

                    ocr_text = await asyncio.to_thread(_extract_pdf_text)
            except Exception:
                pass

        # 4) result/ í˜ì´ì§€ JSONì˜ text í•„ë“œ ì‹œë„
        if not ocr_text.strip():
            try:
                from modules.core.storage import PageStorage
                page_data = PageStorage.load_page(pdf_name, page_number)
                if page_data and isinstance(page_data.get("text"), str):
                    ocr_text = page_data["text"]
            except Exception:
                pass

        return {"ocr_text": ocr_text or ""}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class RerunOcrBody(BaseModel):
    """OCR ë‹¤ì‹œ ì¸ì‹ ìš”ì²­ (ì •ë‹µì§€ íƒ­: Azure ì „ìš©)"""
    provider: str = "azure"  # ì •ë‹µì§€ ì˜ì—­ì—ì„œëŠ” Azureë§Œ ì‚¬ìš©
    azure_model: Optional[str] = None  # prebuilt-read | prebuilt-layout | prebuilt-document (ê¸°ë³¸ prebuilt-layout)


@router.post("/{pdf_filename}/pages/{page_number}/ocr-rerun")
async def rerun_page_ocr(
    pdf_filename: str,
    page_number: int,
    body: RerunOcrBody,
    db=Depends(get_db),
):
    """
    í˜„ì¬ í˜ì´ì§€ì— ëŒ€í•´ Azure OCRì„ ë‹¤ì‹œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ debug2ì— ì €ì¥í•œ ë’¤ ë°˜í™˜.
    ì •ë‹µì§€ ìƒì„± íƒ­ ì „ìš© â€” ì €ì¥ë˜ëŠ” OCR í…ìŠ¤íŠ¸ëŠ” í•­ìƒ Azure.
    """
    provider = (body.provider or "azure").strip().lower()
    if provider != "azure":
        raise HTTPException(status_code=400, detail="ì •ë‹µì§€ ì˜ì—­ì—ì„œëŠ” Azure OCRë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    pdf_name = pdf_filename if not pdf_filename.lower().endswith(".pdf") else pdf_filename[:-4]
    root = Path(__file__).resolve().parent.parent.parent.parent  # project root

    # 1) í˜ì´ì§€ ì´ë¯¸ì§€ ê²½ë¡œ (DB) ë˜ëŠ” PDF ê²½ë¡œ í™•ë³´
    image_path = db.get_page_image_path(pdf_filename, page_number)
    full_image_path = None
    if image_path:
        full_image_path = Path(image_path) if Path(image_path).is_absolute() else root / image_path
        if not full_image_path.exists():
            full_image_path = None

    pdf_path_str = None
    if not full_image_path:
        from modules.utils.pdf_utils import find_pdf_path
        pdf_path_str = find_pdf_path(pdf_name)
    pdf_path = Path(pdf_path_str) if pdf_path_str and Path(pdf_path_str).exists() else None

    if not full_image_path and not pdf_path:
        raise HTTPException(
            status_code=404,
            detail="í˜ì´ì§€ ì´ë¯¸ì§€ ë˜ëŠ” PDFë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ì €ì¥ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.",
        )

    ocr_text = ""

    if provider == "azure":
        try:
            from modules.core.extractors.azure_extractor import get_azure_extractor
            from modules.utils.table_ocr_utils import raw_to_full_text

            azure_model = (body.azure_model or "prebuilt-layout").strip() or "prebuilt-layout"
            extractor = get_azure_extractor(model_id=azure_model, enable_cache=False)
            raw = None
            if full_image_path:
                raw = await asyncio.to_thread(extractor.extract_from_image_raw, image_path=full_image_path)
            elif pdf_path:
                raw = await asyncio.to_thread(
                    extractor.extract_from_pdf_page_raw, pdf_path, page_number
                )
            if raw:
                ocr_text = raw_to_full_text(raw) or ""  # í‘œì‹œìš©: ì¸ì‹í•œ ì „ì²´ ë¬¸ìì—´
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Azure OCR ì‹¤íŒ¨: {e}")

    if not ocr_text.strip():
        raise HTTPException(
            status_code=422,
            detail="OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í’ˆì§ˆ ë˜ëŠ” í˜ì´ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
        )

    # debug2ì— ì €ì¥í•˜ì—¬ ì´í›„ get_page_ocr_textì—ì„œ ì´ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•¨
    debug2_dir = root / "debug2" / pdf_name
    debug2_dir.mkdir(parents=True, exist_ok=True)
    ocr_file = debug2_dir / f"page_{page_number}_ocr_text.txt"
    ocr_file.write_text(ocr_text, encoding="utf-8")

    return {"ocr_text": ocr_text}
